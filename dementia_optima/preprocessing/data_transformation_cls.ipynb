{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as spstats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from ast import literal_eval\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransform():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.feature_funcs = {'conti':self.transform_conti_data, 'count':self.transform_count_data,\n",
    "                     'scale':self.transform_scale_data, 'bin':self.transform_bin_data,\n",
    "                     'log':self.transform_log_data, 'nominal':self.transform_nominal_data,\n",
    "                     'ordinal':self.transform_ordinal_data, 'hash': self.transform_hash_data,\n",
    "                     'ordinaltolabel':self.transform_ordinal_data_label, 'multiLabel':self.transform_multilabel_data,\n",
    "                     'oneHot':self.transform_onehot_data, 'transtolist':self.transform_to_listdata, 'default':self.show_dataframe}\n",
    "    \n",
    "    def wrap(pre, post):\n",
    "        \"\"\" Wrapper \"\"\"\n",
    "        def decorate(func):\n",
    "            \"\"\" Decorator \"\"\"\n",
    "            def call(*args, **kwargs):\n",
    "                \"\"\" Actual wrapping \"\"\"\n",
    "                pre(func)\n",
    "                result = func(*args, **kwargs)\n",
    "                post(func)\n",
    "                return result\n",
    "            return call\n",
    "        return decorate\n",
    "    \n",
    "    def entering(func):\n",
    "        \"\"\" Pre function logging \"\"\"\n",
    "        # print(\"Entered: \", func.__name__)\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def exiting(func):\n",
    "        \"\"\" Post function logging \"\"\"\n",
    "        # print(\"Exited: \", func.__name__)\n",
    "        pass\n",
    "\n",
    "    @wrap(entering, exiting)    \n",
    "    def transform_conti_data(self, **kwargs):\n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        return feature_arr\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_count_data(self, **kwargs):\n",
    "        feature_arr = self.df[kwargs['column_name']] > kwargs['threshold'] \n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        return feature_arr\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_scale_data(self, **kwargs):\n",
    "        feature_arr = self.df[kwargs['column_name']]/kwargs['factor']\n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        return feature_arr\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_bin_data(self, **kwargs):\n",
    "        \n",
    "        enc = KBinsDiscretizer(kwargs['n_bins'], kwargs['encode'], kwargs['strategy'])\n",
    "        feature_arr_enc = enc.fit_transform(self.df[[kwargs['column_name']]].dropna()).flatten()\n",
    "        #print (type(feature_arr_enc))\n",
    "        feature_arr = pd.cut(self.df[kwargs['column_name']], np.concatenate(enc.bin_edges_, axis=0), right=False)\n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        return feature_arr\n",
    "\n",
    "    @wrap(entering, exiting)    \n",
    "    def transform_log_data(self, **kwargs):\n",
    "        feature_arr = np.log(self.df[kwargs['column_name']])\n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        return feature_arr\n",
    "    \n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_nominal_data(self, **kwargs):\n",
    "        enc = OneHotEncoder(categories='auto', handle_unknown='ignore').fit(self.df[[kwargs['column_name']]].dropna())\n",
    "        print (enc.categories_)\n",
    "        feature_arr = enc.transform(self.df[[kwargs['column_name']]].replace([np.nan], [-1])).toarray()\n",
    "        # print (feature_arr)\n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        return feature_arr\n",
    "        \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_ordinal_data_label(self, **kwargs):\n",
    "        feature_arr = self.df[kwargs['column_name']].map(kwargs['order'])\n",
    "        self.add_column_df(kwargs['column_name'], feature_arr, '-Label')\n",
    "        return feature_arr\n",
    "        \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_ordinal_data(self, **kwargs):\n",
    "        enc = OneHotEncoder(categories='auto', handle_unknown='ignore').fit(self.df[[kwargs['column_name']]].dropna())\n",
    "        feature_arr = enc.fit_transform(self.df[[kwargs['column_name']]].replace([np.nan], [[]])).toarray()\n",
    "        \n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        return feature_arr\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_hash_data(self, **kwargs):\n",
    "        enc = FeatureHasher(n_features=kwargs['n_features'], input_type='string')\n",
    "        feature_arr = enc.fit_transform(\n",
    "                              self.df[kwargs['column_name']]).toarray()\n",
    "        #print (feature_arr)\n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        return feature_arr\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_to_listdata(self, **kwargs):\n",
    "        return feature_arr\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_multilabel_data(self, **kwargs):\n",
    "        #feature_arr = self.feature_funcs[kwargs['data_type_func']](**kwargs)\n",
    "        #feature_arr = []\n",
    "        mlb = MultiLabelBinarizer(classes=kwargs['classes'])\n",
    "        if kwargs['literal'] == True:\n",
    "            mlb.fit(self.df[kwargs['column_name']].dropna().apply(literal_eval))\n",
    "            feature_arr = mlb.transform(self.df[kwargs['column_name']].replace([np.nan], ['[]']).apply(literal_eval))\n",
    "        else:\n",
    "            mlb.fit(self.df[kwargs['column_name']].dropna())\n",
    "            feature_arr = mlb.transform(self.df[kwargs['column_name']].replace([np.nan], ['[]']))\n",
    "        self.add_column_df(kwargs['column_name'], feature_arr)\n",
    "        tf_df = pd.DataFrame(feature_arr, columns=[kwargs['column_name']+'_TFV_'+cls for cls in mlb.classes_],\n",
    "                             index=self.df.index)\n",
    "        \n",
    "        ## Todo change columns name\n",
    "        #tf_df = tf_df[[kwargs['column_name']+'_'+col+'_TRV_' for col in tf_df.columns.tolist()]]\n",
    "        self.add_column_after(kwargs['column_name']+'_TF_', tf_df)\n",
    "        \n",
    "        return tf_df\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def transform_onehot_data(self, **kwargs):\n",
    "        feature_arr = self.feature_funcs[kwargs['data_type_func']](**kwargs)\n",
    "        \n",
    "        if kwargs['data_type_func'] == 'bin':\n",
    "            print ('bin data')\n",
    "            tf_df = pd.get_dummies(data=pd.DataFrame(data=feature_arr, columns=[kwargs['column_name']]), prefix_sep='_TFV_')\n",
    "        elif(self.df[[kwargs['column_name']]].dtypes.iloc[0]==np.bool):\n",
    "            print('boolean data')\n",
    "            tf_df = pd.get_dummies(data=self.df[[kwargs['column_name']]].replace([False, True], ['False', 'True']), prefix_sep='_TFV_')\n",
    "        else:\n",
    "            tf_df = pd.get_dummies(data=self.df[[kwargs['column_name']]], prefix_sep='_TFV_')\n",
    "        \n",
    "        \n",
    "        self.add_column_after(kwargs['column_name']+'_TF_', tf_df)\n",
    "        \n",
    "        #return feature_arr\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def getFile(self, **kwargs):\n",
    "        return self.file\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def plotData(self,plottype, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def get_data_frame(self):\n",
    "        return self.df\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def set_data_frame(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def add_column_df(self, column_name, feature_arr, suffix='_TF_'):\n",
    "        #feature_arr_T = feature_arr.transpose()\n",
    "        #[self.df.insert(loc=df.columns.get_loc(column_name)+1+i, column=column_name[0:2]+str(i), value=new_col) \n",
    "                                                #for i, new_col in zip(range(len(feature_arr_T)), feature_arr_T)]\n",
    "        self.df.insert(loc=self.df.columns.get_loc(column_name)+1, column=column_name+suffix, value=feature_arr.tolist())\n",
    "        #self.df = self.df.assign(e=feature_arr)\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def add_column_after(self, column_name, tf_df):\n",
    "        pre_df = self.df.iloc[:,0:self.df.columns.get_loc(column_name)+1]\n",
    "        post_df =self.df.iloc[:,self.df.columns.get_loc(column_name)+1:]\n",
    "        tf_df[pd.isna(pre_df.iloc[:,-2])]=np.nan\n",
    "        self.df = pd.concat([pre_df, tf_df, post_df], axis=1)\n",
    "\n",
    "    \n",
    "    @wrap(entering, exiting)\n",
    "    def show_dataframe(self, n=5):\n",
    "        #print(self.df.head(n))\n",
    "        display(self.df.head(n))\n",
    "        \n",
    "    \n",
    "    @wrap(entering, exiting)    \n",
    "    def extract_value_frm_list(self, x):\n",
    "        clss = set()\n",
    "        for l in list(x):\n",
    "            try:\n",
    "                for ll in list(l):\n",
    "                    clss.add(str(ll))\n",
    "            except Exception as e:\n",
    "                print ('', end='')\n",
    "        #print (clss)        \n",
    "        return list(clss)\n",
    "        \n",
    "        \n",
    "    @wrap(entering, exiting)\n",
    "    def apply_feature_transform(self, **kwargs):\n",
    "        '''try:\n",
    "            print('Transformation Column Name: {}, Function Type: {}'.format(kwargs['column_name'],kwargs['func_type']))\n",
    "            feature_funcs[kwargs['func_type']](**kwargs)\n",
    "        except:\n",
    "            print('Error: No Feature Transformation')\n",
    "            feature_funcs['default']'''\n",
    "        self.feature_funcs[kwargs['func_type']](**kwargs)\n",
    "        return self.get_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
